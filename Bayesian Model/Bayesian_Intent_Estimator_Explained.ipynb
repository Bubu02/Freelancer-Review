{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8544a3",
   "metadata": {},
   "source": [
    "# Bayesian Intent Estimator ‚Äî Explained Notebook\n",
    "This notebook mirrors the `bayesian_intent_estimator.py` script with explanations before each section."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1. Introduction to the Bayesian Model**\n",
    "\n",
    "A **Bayesian Network (BN)** is a probabilistic graphical model that represents how variables influence one another.\n",
    "Each node is a variable (like device type, added_to_cart, or intent), and each directed edge encodes a dependency (for example, reached_checkout ‚Üí intent).\n",
    "Instead of learning a single global regression function, the BN learns a conditional probability table (CPT) for each node‚Äîhow likely it is to take a given value, given its parents.\n",
    "This allows the model to:\n",
    "\n",
    "1. Work naturally with mixed categorical data,\n",
    "\n",
    "2. Express uncertainty explicitly,\n",
    "\n",
    "3. Handle missing evidence gracefully.\n",
    "\n",
    "4. Be inspected and interpreted directly (CPTs are human-readable)."
   ],
   "id": "79dc74512a0b2713"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## **2. How This Bayesian Intent Estimator Was Developed**\n",
    "\n",
    "The implementation (bayesian_intent_estimator.py) was written from scratch using the pgmpy library.\n",
    "The pipeline is intentionally simple and transparent:"
   ],
   "id": "10b7ecc932026816"
  },
  {
   "cell_type": "markdown",
   "id": "7f3ef9f9",
   "metadata": {},
   "source": "### Imports & pgmpy compatibility"
  },
  {
   "cell_type": "code",
   "id": "08852e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.528934Z",
     "start_time": "2025-11-06T07:46:27.405739Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, brier_score_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pgmpy shuffled names around in newer releases; keep this import robust.\n",
    "try:\n",
    "    from pgmpy.models import BayesianNetwork  # <= 0.1.24\n",
    "except Exception:\n",
    "    from pgmpy.models.BayesianNetwork import BayesianNetwork  # >= 0.1.25\n",
    "\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.inference import VariableElimination"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "93a78d81",
   "metadata": {},
   "source": "### Configuration & Logging"
  },
  {
   "cell_type": "code",
   "id": "1863a3a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.591345Z",
     "start_time": "2025-11-06T07:46:27.537027Z"
    }
   },
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainConfig:\n",
    "    test_size: float = 0.2\n",
    "    seed: int = 42\n",
    "    # Small equivalent sample size adds a bit of smoothing to CPTs\n",
    "    cpd_equiv_n: float = 1.0\n",
    "    outdir: Path = Path(\"./bn_out\")\n",
    "\n",
    "\n",
    "def setup_logging(level: str = \"INFO\") -> None:\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, level.upper(), logging.INFO),\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• Brief Explanation\n",
    "- TrainConfig keeps our model‚Äôs configuration clean, centralized, and unchangeable.\n",
    "\n",
    "- setup_logging() gives us clear, timestamped progress messages instead of random print statements."
   ],
   "id": "c5435c1c5aeb7885"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `@dataclass` and `setup_logging`\n",
    "\n",
    "Let me explain what this part of the code does step by step.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ The `@dataclass(frozen=True)` ‚Äî what it means**\n",
    "\n",
    "This part defines a **configuration class** called `TrainConfig`.\n",
    "It uses Python‚Äôs `@dataclass` decorator, which automatically creates an initializer (`__init__`) and other helper methods for us.\n",
    "\n",
    "The `frozen=True` argument means that once I create an instance of this class, I **cannot modify its values later** ‚Äî it becomes **immutable**.\n",
    "This is really helpful for reproducibility because it prevents accidental changes to important settings during training.\n",
    "\n",
    "Here‚Äôs what each parameter inside `TrainConfig` represents:\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|------------|------|----------|-------------|\n",
    "| `test_size` | `float` | `0.2` | This decides how much of the dataset is used for testing. Here it‚Äôs 20%. |\n",
    "| `seed` | `int` | `42` | This is the random seed that ensures results stay the same every time we run the model. |\n",
    "| `cpd_equiv_n` | `float` | `1.0` | This controls smoothing in the Bayesian model‚Äôs Conditional Probability Tables (CPTs). It helps avoid zero probabilities when data is sparse. |\n",
    "| `outdir` | `Path` | `\"./bn_out\"` | This is the folder where all outputs (like CPTs and predictions) will be saved. |\n",
    "\n",
    "In short, this small class keeps all important training settings **in one place** and ensures they don‚Äôt get changed by mistake.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2Ô∏è‚É£ The `setup_logging` function**\n",
    "\n",
    "This function configures **how messages are printed during the run** ‚Äî it replaces messy `print()` statements with structured, timestamped logs.\n",
    "\n",
    "Here‚Äôs what happens:\n",
    "\n",
    "```python\n",
    "def setup_logging(level: str = \"INFO\") -> None:\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, level.upper(), logging.INFO),\n",
    "        format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    )"
   ],
   "id": "7343a9c0ac53a32d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Step 1 ‚Äì Data Preparation**\n",
    "\n",
    "If no dataset is provided, the script generates a small synthetic e-commerce funnel with variables such as:\n",
    "traffic_source ‚Üí used_search ‚Üí applied_filters ‚Üí added_to_cart ‚Üí reached_checkout ‚Üí intent.\n",
    "\n",
    "Continuous values are discretized (split into quartile bins), and booleans/integers are cast to categorical strings so that pgmpy can learn proper CPTs."
   ],
   "id": "7ac9554847344768"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data helpers (synthetic / load / discretize)",
   "id": "663e02c78eb1f3de"
  },
  {
   "cell_type": "code",
   "id": "cd5250af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.655731Z",
     "start_time": "2025-11-06T07:46:27.613638Z"
    }
   },
   "source": [
    "def make_synthetic(n: int = 2500, seed: int = 42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    traffic_source = rng.choice([\"search\", \"ads\", \"direct\", \"social\"], size=n, p=[0.45, 0.25, 0.20, 0.10])\n",
    "    device = rng.choice([\"mobile\", \"desktop\"], size=n, p=[0.65, 0.35])\n",
    "    prior_purchaser = rng.choice([0, 1], size=n, p=[0.80, 0.20])\n",
    "\n",
    "    used_search = (traffic_source == \"search\").astype(int)\n",
    "    applied_filters = (used_search * (rng.random(n) < 0.6)).astype(int)\n",
    "    added_to_cart = ((applied_filters | (rng.random(n) < 0.15)) * (rng.random(n) < 0.5)).astype(int)\n",
    "    reached_checkout = (added_to_cart * (rng.random(n) < 0.55)).astype(int)\n",
    "    viewed_shipping = ((reached_checkout | (rng.random(n) < 0.1)) * (rng.random(n) < 0.7)).astype(int)\n",
    "\n",
    "    base = 0.05 + 0.40 * reached_checkout + 0.15 * prior_purchaser + 0.05 * (device == \"desktop\")\n",
    "    intent = (rng.random(n) < np.clip(base, 0, 0.95)).astype(int)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"traffic_source\": traffic_source,\n",
    "            \"device\": device,\n",
    "            \"prior_purchaser\": prior_purchaser,\n",
    "            \"used_search\": used_search,\n",
    "            \"applied_filters\": applied_filters,\n",
    "            \"added_to_cart\": added_to_cart,\n",
    "            \"reached_checkout\": reached_checkout,\n",
    "            \"viewed_shipping\": viewed_shipping,\n",
    "            \"intent\": intent,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def load_or_make(path: str | None) -> pd.DataFrame:\n",
    "    if path is None:\n",
    "        logging.info(\"No --data provided; generating a small synthetic dataset.\")\n",
    "        return make_synthetic()\n",
    "    df = pd.read_csv(path)\n",
    "    if \"intent\" not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a binary column named 'intent'.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_discrete(df: pd.DataFrame, target: str) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if c == target:\n",
    "            continue\n",
    "        if pd.api.types.is_integer_dtype(out[c]) or pd.api.types.is_bool_dtype(out[c]):\n",
    "            out[c] = out[c].astype(int).astype(str)\n",
    "        elif pd.api.types.is_float_dtype(out[c]):\n",
    "            try:\n",
    "                out[c] = pd.qcut(out[c], q=4, duplicates=\"drop\").astype(str)\n",
    "            except Exception:\n",
    "                out[c] = out[c].astype(str)\n",
    "        else:\n",
    "            out[c] = out[c].astype(str)\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• Brief Explanation\n",
    "\n",
    "These three functions handle how the dataset is prepared before training the Bayesian model.\n",
    "The `make_synthetic()` function creates a small, realistic, fake dataset that simulates a user‚Äôs online shopping behavior ‚Äî from visiting a site to reaching checkout and showing purchase intent.\n",
    "The `load_or_make()` function either loads a real CSV dataset (if provided) or automatically calls `make_synthetic()` to generate data when none is available.\n",
    "Finally, the `ensure_discrete()` function makes sure all features are converted into **discrete (categorical)** values, since Bayesian Networks require categorical inputs.\n",
    "Together, they make sure the model always has consistent, ready-to-use data, even if no real dataset is provided."
   ],
   "id": "7846a5bf5eceee76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `make_synthetic`, `load_or_make`, and `ensure_discrete`\n",
    "\n",
    "Let me explain what these three functions do and how they work together to prepare our data.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ The `make_synthetic()` function**\n",
    "\n",
    "This function **creates a small, artificial dataset** that simulates a typical **e-commerce funnel**.\n",
    "It‚Äôs helpful when we don‚Äôt have real-world data but still want to train and test the model.\n",
    "\n",
    "Let‚Äôs break it down step by step:\n",
    "\n",
    "- `rng = np.random.default_rng(seed)`\n",
    "  Creates a **random number generator** with a fixed seed, so the synthetic data is the same every time we run the code.\n",
    "\n",
    "- The next few lines create simulated user attributes:\n",
    "  ```python\n",
    "  traffic_source = rng.choice([\"search\", \"ads\", \"direct\", \"social\"], size=n, p=[0.45, 0.25, 0.20, 0.10])\n",
    "  device = rng.choice([\"mobile\", \"desktop\"], size=n, p=[0.65, 0.35])\n",
    "  prior_purchaser = rng.choice([0, 1], size=n, p=[0.80, 0.20])"
   ],
   "id": "85665ececcd5c587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Step 2 ‚Äì DAG Construction**\n",
    "A hand-crafted, interpretable funnel-shaped DAG defines the main dependencies:"
   ],
   "id": "54cb66248aa41950"
  },
  {
   "cell_type": "code",
   "id": "9dd4c0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.686478Z",
     "start_time": "2025-11-06T07:46:27.669816Z"
    }
   },
   "source": [
    "def build_dag(features: List[str], target: str = \"intent\") -> BayesianNetwork:\n",
    "    nodes = set(features) | {target}\n",
    "\n",
    "    def have(*cols: str) -> bool:\n",
    "        return all(c in nodes for c in cols)\n",
    "\n",
    "    edges: List[Tuple[str, str]] = []\n",
    "    if have(\"traffic_source\", \"used_search\"):\n",
    "        edges.append((\"traffic_source\", \"used_search\"))\n",
    "    if have(\"used_search\", \"applied_filters\"):\n",
    "        edges.append((\"used_search\", \"applied_filters\"))\n",
    "    if have(\"applied_filters\", \"added_to_cart\"):\n",
    "        edges.append((\"applied_filters\", \"added_to_cart\"))\n",
    "    if have(\"added_to_cart\", \"reached_checkout\"):\n",
    "        edges.append((\"added_to_cart\", \"reached_checkout\"))\n",
    "\n",
    "    for parent in [\"reached_checkout\", \"viewed_shipping\", \"prior_purchaser\", \"device\"]:\n",
    "        if have(parent, target):\n",
    "            edges.append((parent, target))\n",
    "\n",
    "    for f in features:\n",
    "        if f != target and not any(p == f and c == target for p, c in edges):\n",
    "            edges.append((f, target))\n",
    "\n",
    "    return BayesianNetwork(edges)\n",
    "\n",
    "\n",
    "def fit_bn(\n",
    "    train: pd.DataFrame,\n",
    "    features: List[str],\n",
    "    target: str,\n",
    "    equiv_n: float,\n",
    ") -> tuple[BayesianNetwork, VariableElimination]:\n",
    "    model = build_dag(features, target)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        model.fit(\n",
    "            train[features + [target]],\n",
    "            estimator=BayesianEstimator,\n",
    "            prior_type=\"BDeu\",\n",
    "            equivalent_sample_size=equiv_n,\n",
    "        )\n",
    "    return model, VariableElimination(model)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• **Brief Paragraph Explanation**\n",
    "\n",
    "- The `build_dag()` function defines the structure of the Bayesian Network by connecting features in a logical sequence that represents a customer‚Äôs journey ‚Äî from visiting the site to reaching checkout and showing purchase intent. It adds edges between related variables and connects every feature to the target (`intent`) so nothing is left out.\n",
    "- The `fit_bn()` function then trains this network using pgmpy‚Äôs `BayesianEstimator`, which learns the conditional probability tables (CPTs) from the data. It applies a small Bayesian prior (BDeu) for smoothing and returns both the trained model and an inference object to compute probabilities later. Together, these functions build and train the probabilistic model that underpins the intent prediction system."
   ],
   "id": "4ab2822d9ec038ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `build_dag()` and `fit_bn()`\n",
    "\n",
    "Let me explain how these two functions work together to construct and train the Bayesian Network model.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ The `build_dag()` function**\n",
    "\n",
    "This function builds the **Directed Acyclic Graph (DAG)** ‚Äî the structure that defines how variables influence each other in the Bayesian Network.\n",
    "A DAG is a set of nodes (variables) connected by directed edges that represent causal or dependency relationships.\n",
    "\n",
    "Here‚Äôs what happens step-by-step:\n",
    "\n",
    "- `nodes = set(features) | {target}`\n",
    "  This collects all the features plus the target (in our case, `intent`) into one set of nodes for the network.\n",
    "\n",
    "- `have(*cols)`\n",
    "  This small helper function simply checks if all the mentioned columns exist in the current dataset before trying to connect them.\n",
    "  It makes the function flexible, so if a dataset is missing a column, it doesn‚Äôt crash.\n",
    "\n",
    "- Then we define the main **edges** ‚Äî the relationships between features ‚Äî in a way that mimics a user‚Äôs online shopping funnel:\n",
    "  ```python\n",
    "  traffic_source ‚Üí used_search ‚Üí applied_filters ‚Üí added_to_cart ‚Üí reached_checkout"
   ],
   "id": "95c1849a266d0ef1"
  },
  {
   "cell_type": "markdown",
   "id": "904dcde2",
   "metadata": {},
   "source": [
    "## Inference utilities"
   ]
  },
  {
   "cell_type": "code",
   "id": "9887717f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.730695Z",
     "start_time": "2025-11-06T07:46:27.710636Z"
    }
   },
   "source": [
    "def _p1_from_query(q) -> float:\n",
    "    vals = np.asarray(q.values).ravel()\n",
    "    names = q.state_names.get(list(q.variables)[0], None)\n",
    "    if names is None:\n",
    "        return float(vals[-1])\n",
    "    if \"1\" in names:\n",
    "        return float(vals[names.index(\"1\")])\n",
    "    if 1 in names:\n",
    "        return float(vals[names.index(1)])\n",
    "    try:\n",
    "        idx = int(np.argmax([float(str(s)) for s in names]))\n",
    "    except Exception:\n",
    "        idx = len(names) - 1\n",
    "    return float(vals[idx])\n",
    "\n",
    "\n",
    "def predict_proba(infer: VariableElimination, X: pd.DataFrame, target: str) -> np.ndarray:\n",
    "    X = X.reset_index(drop=True)\n",
    "    out = np.zeros(len(X), dtype=float)\n",
    "    for i, row in enumerate(X.itertuples(index=False, name=None)):\n",
    "        evidence = {c: v for c, v in zip(X.columns, row) if pd.notna(v)}\n",
    "        q = infer.query([target], evidence=evidence, show_progress=False)\n",
    "        out[i] = _p1_from_query(q)\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• Brief Explanation\n",
    "\n",
    "- These two functions work together to calculate the predicted probability of the target (for example, `intent = 1`) using the trained Bayesian Network.\n",
    "The `_p1_from_query()` function extracts the probability of the positive class (`1`) from pgmpy‚Äôs query results, handling different naming formats safely.\n",
    "The `predict_proba()` function then loops through each row in the dataset, builds an evidence dictionary for the model, performs inference using `VariableElimination`, and uses `_p1_from_query()` to record the probability of intent for each observation.\n",
    "In short, they convert the Bayesian Network‚Äôs learned relationships into actual **numerical probability predictions** for every data sample."
   ],
   "id": "d1ae085d6cd2ef5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `_p1_from_query()` and `predict_proba()`\n",
    "\n",
    "Let‚Äôs go through these two functions ‚Äî they work together to calculate the **predicted probability of intent** for each observation.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ The `_p1_from_query()` function**\n",
    "\n",
    "This is a **helper function** that extracts the probability of the target being `1` (for example, `intent = 1`) from pgmpy‚Äôs query output.\n",
    "\n",
    "When we use pgmpy‚Äôs inference engine (`VariableElimination`), it returns a **query object** containing:\n",
    "- All possible states of a variable (e.g., `\"0\"` and `\"1\"`)\n",
    "- Their associated probabilities.\n",
    "\n",
    "This helper ensures we always pick the correct probability value, even if the states are labeled differently (as strings `\"1\"`, integers `1`, or in another order).\n",
    "\n",
    "Here‚Äôs what it does step by step:\n",
    "1. `vals = np.asarray(q.values).ravel()` ‚Üí flattens the array of probabilities returned by the query.\n",
    "2. `names = q.state_names.get(list(q.variables)[0], None)` ‚Üí retrieves the possible state names (like `[\"0\", \"1\"]`).\n",
    "3. Then it checks several possibilities:\n",
    "   - If `\"1\"` exists in the list, return its probability.\n",
    "   - If integer `1` exists, return that.\n",
    "   - Otherwise, it tries to find the **largest numeric value** (assuming `1` represents the positive class).\n",
    "4. If all else fails, it simply takes the **last value** as a fallback.\n",
    "\n",
    "This makes the function **robust** to different output formats and ensures it always returns a single float ‚Äî `P(target=1)`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2Ô∏è‚É£ The `predict_proba()` function**\n",
    "\n",
    "This function uses the trained Bayesian Network‚Äôs inference engine to **predict probabilities** for each observation in a dataset.\n",
    "\n",
    "Here‚Äôs the breakdown:\n",
    "\n",
    "1. **Reset indices:**\n",
    "   ```python\n",
    "   X = X.reset_index(drop=True)"
   ],
   "id": "4984e32777a269f3"
  },
  {
   "cell_type": "markdown",
   "id": "3adee6c9",
   "metadata": {},
   "source": [
    "## Export CPTs (wide & long)"
   ]
  },
  {
   "cell_type": "code",
   "id": "277badd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.768251Z",
     "start_time": "2025-11-06T07:46:27.752741Z"
    }
   },
   "source": [
    "def export_cpt(model: BayesianNetwork, node: str, outdir: Path) -> None:\n",
    "    cpd = model.get_cpds(node)\n",
    "\n",
    "    child_states = cpd.state_names.get(node, [])\n",
    "    child_states = [str(s) for s in child_states] if child_states else [str(i) for i in range(cpd.cardinality[0])]\n",
    "\n",
    "    parents = cpd.variables[:-1]\n",
    "    parent_states = [cpd.state_names[p] for p in parents] if parents else []\n",
    "\n",
    "    if parents:\n",
    "        cols = pd.MultiIndex.from_tuples(list(product(*parent_states)), names=[str(p) for p in parents])\n",
    "    else:\n",
    "        cols = pd.Index([\"<no_parents>\"])\n",
    "\n",
    "    vals = cpd.get_values()\n",
    "    cpt_wide = pd.DataFrame(vals, index=child_states, columns=cols)\n",
    "    cpt_wide.index.name = f\"{node}_state\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    cpt_wide.to_csv(outdir / f\"{node}_cpt_wide.csv\")\n",
    "\n",
    "    if parents:\n",
    "        cpt_long = (\n",
    "            cpt_wide\n",
    "            .stack(list(range(len(parents))))\n",
    "            .rename(\"prob\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        cpt_long.columns = [f\"{node}_state\"] + [str(p) for p in parents] + [\"prob\"]\n",
    "    else:\n",
    "        cpt_long = pd.DataFrame({f\"{node}_state\": child_states, \"prob\": vals.ravel()})\n",
    "\n",
    "    cpt_long.to_csv(outdir / f\"{node}_cpt_long.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• **Brief Paragraph Explanation**\n",
    "\n",
    "- The `export_cpt()` function extracts the Conditional Probability Table (CPT) of a selected node (for example, `intent`) from the trained Bayesian Network and saves it into two CSV files. The first is a **wide format** table showing probabilities for every combination of parent states, and the second is a **long (tidy)** format table suitable for visualization and further analysis. In simple terms, this function converts the Bayesian model‚Äôs learned probabilities into human-readable tables so we can clearly see how each parent variable influences the target.\n"
   ],
   "id": "c9c265aae1091be1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `export_cpt()`\n",
    "\n",
    "This function exports the **Conditional Probability Table (CPT)** of a specific node (variable) from the trained Bayesian Network into two easy-to-read CSV files ‚Äî one in a *wide* format and one in a *long* format.\n",
    "These outputs make it possible to inspect, analyze, or visualize how each parent variable influences the target.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step-by-step explanation**\n",
    "\n",
    "1. **Access the node‚Äôs CPD (Conditional Probability Distribution):**\n",
    "   ```python\n",
    "   cpd = model.get_cpds(node)"
   ],
   "id": "9d0ed54aa19df1ab"
  },
  {
   "cell_type": "markdown",
   "id": "ccdf19d4",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6263cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:27.809028Z",
     "start_time": "2025-11-06T07:46:27.792412Z"
    }
   },
   "source": [
    "def eval_probs(y_true: Iterable[int], p: np.ndarray) -> dict:\n",
    "    y = np.asarray(list(y_true)).astype(int)\n",
    "    return {\n",
    "        \"AUROC\": round(roc_auc_score(y, p), 4),\n",
    "        \"AUPR\": round(average_precision_score(y, p), 4),\n",
    "        \"Brier\": round(brier_score_loss(y, p), 4),\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• **Brief Paragraph Explanation**\n",
    "\n",
    "```markdown\n",
    "The `eval_probs()` function evaluates how well the model‚Äôs predicted probabilities match the actual outcomes. It takes the true labels and predicted probabilities, converts them into numeric arrays, and computes three performance metrics: **AUROC** (discrimination ability), **AUPR** (precision-recall balance), and **Brier score** (calibration accuracy). It then returns these scores, rounded to four decimals, providing a quick quantitative summary of how reliable and accurate the model‚Äôs predictions are.\n"
   ],
   "id": "50be79d4cce6b025"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of `eval_probs()`\n",
    "\n",
    "This function evaluates the performance of the Bayesian intent prediction model by comparing the **true labels** (`y_true`) with the **predicted probabilities** (`p`).\n",
    "It computes three key metrics ‚Äî **AUROC**, **AUPR**, and **Brier score** ‚Äî and returns them as a neatly rounded dictionary.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step-by-step explanation**\n",
    "\n",
    "1. **Convert the input labels into a NumPy array:**\n",
    "   ```python\n",
    "   y = np.asarray(list(y_true)).astype(int)"
   ],
   "id": "cb6e330c930665ef"
  },
  {
   "cell_type": "markdown",
   "id": "8ab0cf24",
   "metadata": {},
   "source": [
    "## Demo: train, predict, score on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fdfc7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:53.486084Z",
     "start_time": "2025-11-06T07:46:27.825232Z"
    }
   },
   "source": [
    "setup_logging(\"INFO\")\n",
    "cfg = TrainConfig()\n",
    "df = load_or_make(None)\n",
    "\n",
    "candidates = [\n",
    "    \"traffic_source\", \"device\", \"prior_purchaser\", \"used_search\",\n",
    "    \"applied_filters\", \"added_to_cart\", \"reached_checkout\", \"viewed_shipping\",\n",
    "]\n",
    "features = [c for c in candidates if c in df.columns]\n",
    "target = \"intent\"\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].astype(int)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=cfg.test_size, random_state=cfg.seed, stratify=y)\n",
    "\n",
    "train_disc = ensure_discrete(pd.concat([X_tr, y_tr], axis=1), target=target)\n",
    "val_disc = ensure_discrete(pd.concat([X_va, y_va], axis=1), target=target)\n",
    "\n",
    "model, infer = fit_bn(train_disc, features, target, equiv_n=cfg.cpd_equiv_n)\n",
    "p_val = predict_proba(infer, val_disc[features], target=target)\n",
    "metrics = eval_probs(y_va, p_val)\n",
    "metrics"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No --data provided; generating a small synthetic dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUROC': 0.689, 'AUPR': 0.2948, 'Brier': 0.1207}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• **Brief Paragraph Explanation**\n",
    "\n",
    "- This code block runs the full training and evaluation pipeline for the Bayesian intent model. It starts by setting up logging and configuration, then loads or generates the dataset. The features and target (`intent`) are selected, and the data is split into training and validation sets. Both datasets are discretized for compatibility with the Bayesian Network, which is then trained using `fit_bn()`. After training, `predict_proba()` calculates the probability of purchase intent for each validation record, and `eval_probs()` evaluates the model using AUROC, AUPR, and Brier scores. The final output shows how well the model predicts customer intent.\n"
   ],
   "id": "114029d93fe3d47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of the Training, Prediction, and Evaluation Block\n",
    "\n",
    "This section puts everything together ‚Äî it prepares the data, trains the Bayesian model, makes predictions, and evaluates the results.\n",
    "Let‚Äôs go through it step by step.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ Setting up logging and configuration**\n",
    "```python\n",
    "setup_logging(\"INFO\")\n",
    "cfg = TrainConfig()"
   ],
   "id": "a1f7a53d85f2516"
  },
  {
   "cell_type": "markdown",
   "id": "7f34dd50",
   "metadata": {},
   "source": [
    "## Save predictions & CPTs"
   ]
  },
  {
   "cell_type": "code",
   "id": "3feebbae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:54.062890Z",
     "start_time": "2025-11-06T07:46:53.616870Z"
    }
   },
   "source": [
    "outdir = cfg.outdir\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "pd.DataFrame({\"p_intent\": p_val, \"y\": y_va.to_numpy()}).to_csv(outdir / \"val_predictions.csv\", index=False)\n",
    "export_cpt(model, node=target, outdir=outdir)\n",
    "print(\"Saved to\", outdir.resolve())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to C:\\Users\\mebub_9a7jdi8\\Desktop\\Freelancer\\Bayesian Model\\bn_out\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üê¶‚Äçüî• **Brief Paragraph Explanation**\n",
    "\n",
    "\n",
    "- This block saves the results of the Bayesian model to disk. It first ensures the output directory exists, then writes a CSV file (`val_predictions.csv`) containing the predicted intent probabilities and true labels from the validation set. It also calls `export_cpt()` to save the learned Conditional Probability Tables (CPTs) for the target variable in both wide and long formats. Finally, it prints a confirmation message showing where all the files were saved, completing the model training and export process."
   ],
   "id": "3791b88e1cf86296"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß© Explanation of the Output Saving Block\n",
    "\n",
    "This final block of code saves the key results from the Bayesian Network ‚Äî the predicted probabilities and the learned Conditional Probability Tables (CPTs) ‚Äî into organized files for later use or analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1Ô∏è‚É£ Setting up the output directory**\n",
    "```python\n",
    "outdir = cfg.outdir\n",
    "outdir.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "ba3b8cb8991950fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T07:46:54.091180Z",
     "start_time": "2025-11-06T07:46:54.082531Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5ded952e6b7b5399",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
